{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9243dedf-9452-46c4-aa9b-d7479c49d3cb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import DadosIO as Db\n",
    "import Function as ut_f\n",
    "from pyspark.sql import functions as f\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.window import Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fd4bd43d-69cf-4a3b-b654-ab3bb958677c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(adj_cluster=98.87271118164062, close=102.47000122070312, High=102.95999908447266, low=101.80999755859375, open=101.91000366210938, volume=7559200, dt_carga='20241105')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "df = ut_f.filtro_ultimas_particoes(spark, \n",
    "                                           'sandbox.silver_acoes_disney', \n",
    "                                           nm_particao='dt_carga', \n",
    "                                           qtd_dias_filtro=3, \n",
    "                                           delta=True)\n",
    "\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f3a31c57-70a5-4fc0-9414-f4fdd8231b13",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "feature_columns = df.columns[:-1]\n",
    "assembler = VectorAssembler(inputCols=feature_columns,outputCol=\"features\")\n",
    "df = assembler.transform(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4f9e4770-24be-4ef2-a4cc-b95691115515",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "train, test = df.randomSplit([0.7, 0.3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1ad6c39e-95e0-43ef-9724-e402db7c0e7d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "lr = LinearRegression(featuresCol = 'features', labelCol='volume')\n",
    "lr_model = lr.fit(train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7bf19ee2-890c-4728-9ae3-63021a360bd0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+--------------------+\n|          prediction|  volume|            features|\n+--------------------+--------+--------------------+\n|1.4867900000000011E7|14867900|[79.4235458374023...|\n|   9372500.000000019| 9372500|[79.9593124389648...|\n|1.0291200000000015E7|10291200|[80.0486068725586...|\n|1.1034400000000015E7|11034400|[80.3760299682617...|\n|1.1257600000000015E7|11257600|[80.4157180786132...|\n|2.6579100000000004E7|26579100|[81.8742065429687...|\n|1.1499500000000017E7|11499500|[81.9138946533203...|\n|1.5375100000000013E7|15375100|[82.2909240722656...|\n|1.4316800000000013E7|14316800|[82.5984954833984...|\n| 1.659460000000001E7|16594600|[83.0251312255859...|\n|1.1816600000000011E7|11816600|[83.6204299926757...|\n|1.0808000000000013E7|10808000|[83.6898880004882...|\n|   9554900.000000015| 9554900|[83.6898880004882...|\n|1.1210700000000013E7|11210700|[83.7394943237304...|\n|2.6942599999999996E7|26942600|[83.8387145996093...|\n|1.0047000000000015E7|10047000|[84.0173034667968...|\n| 3.450339999999999E7|34503400|[84.8904113769531...|\n|1.0275100000000013E7|10275100|[85.0392456054687...|\n|           3.22466E7|32246600|[85.0888519287109...|\n| 3.195780000000001E7|31957800|[85.3071365356445...|\n+--------------------+--------+--------------------+\nonly showing top 20 rows\n\nR Squared (R^2) no conjunto de teste = 1\n"
     ]
    }
   ],
   "source": [
    "predictions = lr_model.transform(test)\n",
    "predictions.select(\"prediction\",\"volume\",\"features\").show()\n",
    "\n",
    "test_result = lr_model.evaluate(test)\n",
    "print(\"R Squared (R^2) no conjunto de teste = %g\" % test_result.r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "26ea840f-d098-4569-b324-943ec93b9aa9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.spark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f5cd4158-9d84-4cdb-9676-08d91901663b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/05 16:05:11 INFO mlflow.tracking.fluent: Experiment with name '/teste_modelo_fiap' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='dbfs:/databricks/mlflow-tracking/223413049705617', creation_time=1730822711939, experiment_id='223413049705617', last_update_time=1730822711939, lifecycle_stage='active', name='/teste_modelo_fiap', tags={'mlflow.experiment.sourceName': '/teste_modelo_fiap',\n",
       " 'mlflow.experimentType': 'MLFLOW_EXPERIMENT',\n",
       " 'mlflow.ownerEmail': 't794746@f1rst.com.br',\n",
       " 'mlflow.ownerId': '1353537123434921'}>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_name = \"/teste_modelo_fiap\"\n",
    "mlflow.set_experiment(experiment_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8a65d405-5284-46d7-8ea3-1c80c99ef62b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/11/05 16:05:44 INFO mlflow.spark: Inferring pip requirements by reloading the logged model from the databricks artifact repository, which can be time-consuming. To speed up, explicitly specify the conda_env or pip_requirements when calling log_model().\n2024/11/05 16:06:17 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: dbfs:/databricks/mlflow-tracking/223413049705617/ce48417b7e74417cafd82e39b41a56ab/artifacts/model/sparkml, flavor: spark). Fall back to return ['pyspark==3.5.0']. Set logging level to DEBUG to see the full traceback. \n/databricks/python/lib/python3.11/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\n  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run():\n",
    "    lr = LinearRegression(featuresCol = 'features', labelCol='volume')\n",
    "    lr_model = lr.fit(train)\n",
    "\n",
    "    mlflow.spark.log_model(lr_model, \"model\")\n",
    "\n",
    "    test_result = lr_model.evaluate(test)\n",
    "    mlflow.log_metric(\"r2\", test_result.r2)\n",
    "\n",
    "    #o codigo abaixo registra o modelo\n",
    "    mlflow.register_model(f\"runs:/{mlflow.active_run().info.run_id}/model\", \"model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "899a0636-0348-4a89-8ee3-2d2244fa9e18",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fbec7068-0536-454f-b815-d3e3efa08568",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\nCollecting featuretools\n  Obtaining dependency information for featuretools from https://files.pythonhosted.org/packages/d4/8c/9e000dfc47b28f482ca7742e11b2f44071cc1981429fd88c922eb1172167/featuretools-1.31.0-py3-none-any.whl.metadata\n  Downloading featuretools-1.31.0-py3-none-any.whl.metadata (15 kB)\nRequirement already satisfied: cloudpickle>=1.5.0 in /databricks/python3/lib/python3.11/site-packages (from featuretools) (2.2.1)\nCollecting holidays>=0.17 (from featuretools)\n  Obtaining dependency information for holidays>=0.17 from https://files.pythonhosted.org/packages/52/99/de904580147b409352a98b92ed7d756c500d0818f5f759df741c3b6fa319/holidays-0.60-py3-none-any.whl.metadata\n  Downloading holidays-0.60-py3-none-any.whl.metadata (25 kB)\nCollecting numpy>=1.25.0 (from featuretools)\n  Obtaining dependency information for numpy>=1.25.0 from https://files.pythonhosted.org/packages/7a/f0/80811e836484262b236c684a75dfc4ba0424bc670e765afaa911468d9f39/numpy-2.1.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n  Downloading numpy-2.1.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n\u001B[?25l     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/62.0 kB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\n\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m62.0/62.0 kB\u001B[0m \u001B[31m3.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hRequirement already satisfied: packaging>=20.0 in /databricks/python3/lib/python3.11/site-packages (from featuretools) (23.2)\nCollecting pandas>=2.0.0 (from featuretools)\n  Obtaining dependency information for pandas>=2.0.0 from https://files.pythonhosted.org/packages/cd/5f/4dba1d39bb9c38d574a9a22548c540177f78ea47b32f99c0ff2ec499fac5/pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n  Downloading pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n\u001B[?25l     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/89.9 kB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\n\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m89.9/89.9 kB\u001B[0m \u001B[31m6.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hRequirement already satisfied: psutil>=5.7.0 in /databricks/python3/lib/python3.11/site-packages (from featuretools) (5.9.0)\nRequirement already satisfied: scipy>=1.10.0 in /databricks/python3/lib/python3.11/site-packages (from featuretools) (1.11.1)\nCollecting tqdm>=4.66.3 (from featuretools)\n  Obtaining dependency information for tqdm>=4.66.3 from https://files.pythonhosted.org/packages/41/73/02342de9c2d20922115f787e101527b831c0cffd2105c946c4a4826bcfd4/tqdm-4.66.6-py3-none-any.whl.metadata\n  Downloading tqdm-4.66.6-py3-none-any.whl.metadata (57 kB)\n\u001B[?25l     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/57.6 kB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\n\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m57.6/57.6 kB\u001B[0m \u001B[31m6.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hCollecting woodwork>=0.28.0 (from featuretools)\n  Obtaining dependency information for woodwork>=0.28.0 from https://files.pythonhosted.org/packages/49/a2/bf83836640086a518c6b0c361765aaaf37b57e127844dd57f6c7e9e11153/woodwork-0.31.0-py3-none-any.whl.metadata\n  Downloading woodwork-0.31.0-py3-none-any.whl.metadata (10 kB)\nRequirement already satisfied: python-dateutil in /databricks/python3/lib/python3.11/site-packages (from holidays>=0.17->featuretools) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /databricks/python3/lib/python3.11/site-packages (from pandas>=2.0.0->featuretools) (2022.7)\nCollecting tzdata>=2022.7 (from pandas>=2.0.0->featuretools)\n  Obtaining dependency information for tzdata>=2022.7 from https://files.pythonhosted.org/packages/a6/ab/7e5f53c3b9d14972843a647d8d7a853969a58aecc7559cb3267302c94774/tzdata-2024.2-py2.py3-none-any.whl.metadata\n  Downloading tzdata-2024.2-py2.py3-none-any.whl.metadata (1.4 kB)\nCollecting numpy>=1.25.0 (from featuretools)\n  Obtaining dependency information for numpy>=1.25.0 from https://files.pythonhosted.org/packages/3a/d0/edc009c27b406c4f9cbc79274d6e46d634d139075492ad055e3d68445925/numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n\u001B[?25l     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/61.0 kB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\n\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m61.0/61.0 kB\u001B[0m \u001B[31m5.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hRequirement already satisfied: scikit-learn>=1.1.0 in /databricks/python3/lib/python3.11/site-packages (from woodwork>=0.28.0->featuretools) (1.3.0)\nCollecting importlib-resources>=5.10.0 (from woodwork>=0.28.0->featuretools)\n  Obtaining dependency information for importlib-resources>=5.10.0 from https://files.pythonhosted.org/packages/e1/6a/4604f9ae2fa62ef47b9de2fa5ad599589d28c9fd1d335f32759813dfa91e/importlib_resources-6.4.5-py3-none-any.whl.metadata\n  Downloading importlib_resources-6.4.5-py3-none-any.whl.metadata (4.0 kB)\nRequirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil->holidays>=0.17->featuretools) (1.16.0)\nRequirement already satisfied: joblib>=1.1.1 in /databricks/python3/lib/python3.11/site-packages (from scikit-learn>=1.1.0->woodwork>=0.28.0->featuretools) (1.2.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /databricks/python3/lib/python3.11/site-packages (from scikit-learn>=1.1.0->woodwork>=0.28.0->featuretools) (2.2.0)\nDownloading featuretools-1.31.0-py3-none-any.whl (587 kB)\n\u001B[?25l   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/587.9 kB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\n\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m587.9/587.9 kB\u001B[0m \u001B[31m30.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hDownloading holidays-0.60-py3-none-any.whl (1.1 MB)\n\u001B[?25l   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/1.1 MB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\n\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.1/1.1 MB\u001B[0m \u001B[31m39.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hDownloading pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n\u001B[?25l   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/13.1 MB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\n\u001B[2K   \u001B[91m━━━━━\u001B[0m\u001B[90m╺\u001B[0m\u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.7/13.1 MB\u001B[0m \u001B[31m51.5 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K   \u001B[91m━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m\u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m3.8/13.1 MB\u001B[0m \u001B[31m54.3 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m\u001B[90m━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m6.1/13.1 MB\u001B[0m \u001B[31m57.9 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[90m╺\u001B[0m\u001B[90m━━━━━━━━━━━━━\u001B[0m \u001B[32m8.6/13.1 MB\u001B[0m \u001B[31m61.7 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m\u001B[90m━━━━━\u001B[0m \u001B[32m11.4/13.1 MB\u001B[0m \u001B[31m67.2 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m13.1/13.1 MB\u001B[0m \u001B[31m69.6 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m13.1/13.1 MB\u001B[0m \u001B[31m69.6 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m13.1/13.1 MB\u001B[0m \u001B[31m69.6 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m13.1/13.1 MB\u001B[0m \u001B[31m69.6 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m13.1/13.1 MB\u001B[0m \u001B[31m69.6 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m13.1/13.1 MB\u001B[0m \u001B[31m32.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n\u001B[?25l   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/18.3 MB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\n\u001B[2K   \u001B[91m━━━━━\u001B[0m\u001B[90m╺\u001B[0m\u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.4/18.3 MB\u001B[0m \u001B[31m73.7 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K   \u001B[91m━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m\u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m4.9/18.3 MB\u001B[0m \u001B[31m70.9 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m\u001B[90m━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m7.6/18.3 MB\u001B[0m \u001B[31m75.5 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[90m╺\u001B[0m\u001B[90m━━━━━━━━━━━━━━━\u001B[0m \u001B[32m11.0/18.3 MB\u001B[0m \u001B[31m81.4 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[90m╺\u001B[0m\u001B[90m━━━━━━━━━━\u001B[0m \u001B[32m13.3/18.3 MB\u001B[0m \u001B[31m76.5 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[90m╺\u001B[0m\u001B[90m━━━━\u001B[0m \u001B[32m16.1/18.3 MB\u001B[0m \u001B[31m78.1 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m18.2/18.3 MB\u001B[0m \u001B[31m85.3 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m18.2/18.3 MB\u001B[0m \u001B[31m85.3 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m18.2/18.3 MB\u001B[0m \u001B[31m85.3 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m18.2/18.3 MB\u001B[0m \u001B[31m85.3 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K   \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m18.2/18.3 MB\u001B[0m \u001B[31m85.3 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\n\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m18.3/18.3 MB\u001B[0m \u001B[31m32.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hDownloading tqdm-4.66.6-py3-none-any.whl (78 kB)\n\u001B[?25l   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/78.3 kB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\n\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m78.3/78.3 kB\u001B[0m \u001B[31m7.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hDownloading woodwork-0.31.0-py3-none-any.whl (215 kB)\n\u001B[?25l   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/215.2 kB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\n\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m215.2/215.2 kB\u001B[0m \u001B[31m17.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hDownloading importlib_resources-6.4.5-py3-none-any.whl (36 kB)\nDownloading tzdata-2024.2-py2.py3-none-any.whl (346 kB)\n\u001B[?25l   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/346.6 kB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\n\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m346.6/346.6 kB\u001B[0m \u001B[31m27.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hInstalling collected packages: tzdata, tqdm, numpy, importlib-resources, pandas, holidays, woodwork, featuretools\n  Attempting uninstall: tzdata\n    Found existing installation: tzdata 2022.1\n    Not uninstalling tzdata at /databricks/python3/lib/python3.11/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-086e4ea4-e639-4e8e-931c-4766d40f9164\n    Can't uninstall 'tzdata'. No files were found to uninstall.\n  Attempting uninstall: numpy\n    Found existing installation: numpy 1.23.5\n    Not uninstalling numpy at /databricks/python3/lib/python3.11/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-086e4ea4-e639-4e8e-931c-4766d40f9164\n    Can't uninstall 'numpy'. No files were found to uninstall.\n  Attempting uninstall: pandas\n    Found existing installation: pandas 1.5.3\n    Not uninstalling pandas at /databricks/python3/lib/python3.11/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-086e4ea4-e639-4e8e-931c-4766d40f9164\n    Can't uninstall 'pandas'. No files were found to uninstall.\nSuccessfully installed featuretools-1.31.0 holidays-0.60 importlib-resources-6.4.5 numpy-1.26.4 pandas-2.2.3 tqdm-4.66.6 tzdata-2024.2 woodwork-0.31.0\n\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-223413049705618>, line 7\u001B[0m\n",
       "\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mfeaturetools\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mft\u001B[39;00m\n",
       "\u001B[1;32m      6\u001B[0m es \u001B[38;5;241m=\u001B[39m ft\u001B[38;5;241m.\u001B[39mEntitySet(\u001B[38;5;28mid\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mvolume\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
       "\u001B[0;32m----> 7\u001B[0m es\u001B[38;5;241m.\u001B[39mentity_from_dataframe(entity_id \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdata\u001B[39m\u001B[38;5;124m'\u001B[39m, dataframe \u001B[38;5;241m=\u001B[39m df, \n",
       "\u001B[1;32m      8\u001B[0m                          make_index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m, index \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mindex\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
       "\u001B[1;32m     10\u001B[0m features, feature_defs \u001B[38;5;241m=\u001B[39m ft\u001B[38;5;241m.\u001B[39mdfs(entityset \u001B[38;5;241m=\u001B[39m es, target_entity \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdata\u001B[39m\u001B[38;5;124m'\u001B[39m,\n",
       "\u001B[1;32m     11\u001B[0m                                  trans_primitives \u001B[38;5;241m=\u001B[39m [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124madd_numeric\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmultiply_numeric\u001B[39m\u001B[38;5;124m'\u001B[39m])\n",
       "\n",
       "\u001B[0;31mAttributeError\u001B[0m: 'EntitySet' object has no attribute 'entity_from_dataframe'"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": {
        "ename": "AttributeError",
        "evalue": "'EntitySet' object has no attribute 'entity_from_dataframe'"
       },
       "metadata": {
        "errorSummary": "<span class='ansi-red-fg'>AttributeError</span>: 'EntitySet' object has no attribute 'entity_from_dataframe'"
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [
        "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
        "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
        "File \u001B[0;32m<command-223413049705618>, line 7\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mfeaturetools\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mft\u001B[39;00m\n\u001B[1;32m      6\u001B[0m es \u001B[38;5;241m=\u001B[39m ft\u001B[38;5;241m.\u001B[39mEntitySet(\u001B[38;5;28mid\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mvolume\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m----> 7\u001B[0m es\u001B[38;5;241m.\u001B[39mentity_from_dataframe(entity_id \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdata\u001B[39m\u001B[38;5;124m'\u001B[39m, dataframe \u001B[38;5;241m=\u001B[39m df, \n\u001B[1;32m      8\u001B[0m                          make_index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m, index \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mindex\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m     10\u001B[0m features, feature_defs \u001B[38;5;241m=\u001B[39m ft\u001B[38;5;241m.\u001B[39mdfs(entityset \u001B[38;5;241m=\u001B[39m es, target_entity \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdata\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m     11\u001B[0m                                  trans_primitives \u001B[38;5;241m=\u001B[39m [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124madd_numeric\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmultiply_numeric\u001B[39m\u001B[38;5;124m'\u001B[39m])\n",
        "\u001B[0;31mAttributeError\u001B[0m: 'EntitySet' object has no attribute 'entity_from_dataframe'"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# !pip install featuretools\n",
    "# dbutils.library.restartPython()  \n",
    "\n",
    "# import featuretools as ft\n",
    "\n",
    "# es = ft.EntitySet(id = 'volume')\n",
    "# es.entity_from_dataframe(entity_id = 'data', dataframe = df, \n",
    "#                          make_index = True, index = 'index')\n",
    "\n",
    "# features, feature_defs = ft.dfs(entityset = es, target_entity = 'data',\n",
    "#                                  trans_primitives = ['add_numeric', 'multiply_numeric'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "577e97dc-fda9-4f1b-8ebc-499e2971acb1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": -1,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2
   },
   "notebookName": "modelo",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
